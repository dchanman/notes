{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "## AMD vs Intel\n",
    "* In 2006, AMD had a larger market share (+5%). Suddenly, in 2007, Intel overtook the lead (+14%)\n",
    "* Different architectures provide optimal solutions to certain problems\n",
    "    * AMD for bitcoin mining\n",
    "    * NVDIA for gaming\n",
    "\n",
    "## Introduction\n",
    "Everyone uses MIPS64 instruction set, so it's worth knowing it.\n",
    "\n",
    "### Task of the Computer Designer\n",
    "* Coordinate many levels of abstraction\n",
    "* Under a rapidly changing set of forces\n",
    "* Design, measure, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Principles\n",
    "\n",
    "### *Make the Common Case Fast*\n",
    "* eg. ketchup bottle is upside down so that ketchup is always ready\n",
    "\n",
    "* Compilers (eg. GCC) will actually output different instructions depending on their era. The different combinations are a result of the trends of the current hardware\n",
    "\n",
    "> Two engineers argue. One wants a FP unit that improves division 40x. Another wants a general FP unit that improves everything by 1.5x. Which is better?\n",
    "* Application dependent\n",
    "\n",
    "### *Take Advantage of Parallelism*\n",
    "* **TLP**: Thread level: independent programs run on different processors\n",
    "* **DLP**: Data level: multiple instances of the same program on different input data\n",
    "* **ILP**: Instructions level: different instructions may be run simultaneously\n",
    "* Different parts in a digital circuit can be parallel during a clock cycle (eg. processes in VHDL architecture, pipelining)\n",
    "\n",
    "### *Principle of Locality*\n",
    "Real programs are not completely random; programs have structure and purpose. Many are quite predictable.\n",
    "\n",
    "* eg. programs spend 90% of the time executing 10% of code\n",
    "\n",
    "### *Bang for Buck (!/\\$)*\n",
    "\n",
    "### *Amdahl's Law*\n",
    "Gene Amdahl argued that it was very important to focus on a single processor/core since there is unparallelizable code that will always be the bottleneck.\n",
    "\n",
    "$$ Speedup = \\frac{ExTime_{old}}{ExTime_{new}} = \\frac{1}{(1 - Frac_{enhanced}) + \\frac{Frac_{enh}}{Speedup_{enh}}} $$\n",
    "\n",
    "---\n",
    "\n",
    "# Example: Floating Point (FP) Square Root (FPQSR)\n",
    "\n",
    "* 20% of ExTime due to FPSQR\n",
    "* 50% of ExTime due to **all** FP operations\n",
    "\n",
    "Two options:\n",
    "* Speedup FPSQR by factor of 10\n",
    "* Speedup all FP by a factor of 1.6\n",
    "\n",
    "Result:\n",
    "* FPSQR = 1.22 overall speedup\n",
    "* FP = 1.23 overall speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Tuesday 13 September*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "> Does simulation accuracy limit innovation?\n",
    "\n",
    "If simulations were cycle accurate, we would not be able to measure results. It would take too long.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics of Performance\n",
    "\n",
    "Stack | Care\n",
    "---|---\n",
    "Application | Answers/month, ops/sec\n",
    "Programming language | programs/time\n",
    "Compiler |\n",
    "**ISA** | MIPS/MFLOP/s (millions of instr./s, milions of floating point ops/sec)\n",
    "Datapath control | gigabytes per second\n",
    "Function units, Transistors, wires/pins | cycles per second\n",
    "\n",
    "* Perhaps as an architect, we would make our chip optimized for certain instructions to be faster. Or we prioritize MIPS over MFLOPS.\n",
    "\n",
    "## Definitions\n",
    "* **Performance**: units of things per second. Bigger is better\n",
    "    * Notice there are exceptions. For example, Google might have a high macroscopic request/sec performance. However, each individual request may take too long. In this case, we may want a smaller performance.\n",
    "    * $\\text{Performance}(x) = \\frac{1}{executionTime(x)}$\n",
    "    * $speedup = n = \\frac{performance(x)}{performance(y)} = \\frac{exectime(x)}{exectime(y)}$\n",
    "    * Alternative marketing definitions:\n",
    "        * $perf = \\frac{instructions}{second}$\n",
    "        * $perf = FLOPS$\n",
    "        * $perf = GHz$\n",
    "        * In these cases, maybe something could be clocked faster. However, if it had bad architecture, it could be worse performing compared to slower chips\n",
    "        * Only when comparing two exact architectures may these definitions be interesting\n",
    "* **Benchmarks**: Programs which evaluate performance\n",
    "    * Real applications (eg. weather simulations)\n",
    "        * May take too long to run a full program\n",
    "    * Kernels\n",
    "        * Small key pieces from real programs (eg. linpack)\n",
    "        * Kernel may not be a perfect representative of a program\n",
    "    * Toy benchmarks\n",
    "        * Sieve of Eratosthenes, Puzzle, Quicksort\n",
    "        * Leave these for APSC160/CPSC260, most applications don't spend most of its time doing one specific algorithm\n",
    "    * Synthemtic Benchmarks\n",
    "        * Programs that no customer will ever run\n",
    "        * Poor for sales, since you're not actually building what somebody wants\n",
    "\n",
    "## Benchmark Suites\n",
    "A collection of applications used to measure performance of copmuter\n",
    "\n",
    "Different companies may have different benchmark suites because they're targeting specific goals\n",
    "* What do you want out of a computer?\n",
    "* What programs do you run most often?\n",
    "\n",
    "eg. [SPECint CPU2006](www.spec.org)\n",
    "* 12 applications (gzip, gcc, perl, + other more exotic ones)\n",
    "* Benchmarks update as software improves\n",
    "\n",
    "### Comparing and Summarizing Performance\n",
    " | Computer A | Computer B | Computer C\n",
    " ---|---|---\n",
    " Prog P1 | 1s | 10s | 20s\n",
    " Prog P2 | 1000s | 100s | 20s\n",
    " \n",
    " The fastest computer depends on which program matters for you. **No computer is *fastest overall*.**\n",
    " \n",
    " Typically, large enough companies will get a bunch of samples and run their own benchmarks (eg. Oracle)\n",
    " \n",
    " You can summarize performance using average execution time:\n",
    " $$Average Exec Time = \\frac{1}{n}\\sum_{i=1}^{n}Time_i$$\n",
    " \n",
    " What if you don't run programs 1 and 2 the same number of times?\n",
    " \n",
    " * Use weighted Execution Time\n",
    " \n",
    " $$Weighted Exec Time = \\sum{i=1}{n}Weight_i \\times Time_i$$\n",
    " \n",
    " * Use Geometric Mean\n",
    "     * Execution Time Ratio is the *speedup* for benchmark *i*\n",
    "     * This is the most common one that people use\n",
    " \n",
    " $$Geometric Mean = \\sqrt[n]{\\Pi_{i=1}^{n}ExecutionTimeRatio_i}$$\n",
    " \n",
    " $$\\frac{GeometricMean(X_1, X_2, \\ldots, X_n)}{GeometricMean(Y_1, Y_2, \\ldots, Y_n)} = GeometricMean(\\frac{X_1}{Y_1}, \\frac{X_2}{Y_2}, \\ldots, \\frac{X_n}{Y_n})$$\n",
    " \n",
    "### Example: Weighted Execution Time\n",
    "* The \"fastest\" computer is determined by the weighting of program mix\n",
    "\n",
    "### Example: Arithmetric Mean vs Geometric Mean\n",
    "* Arithmetic mean still allows you to \"cook\" the numbers to make a certain computer faster. The result depends on whichever \"base machine\" you use to base all speedups\n",
    "* Geometric mean will always pick the same machine regardless of the \"base machine\"\n",
    "    * Drawback: geo mean doesn't predict execution time\n",
    "    \n",
    "> *What are we comparing when we use \"Average Performance?\"*\n",
    "> * One computer versus another computer across a set of different programs\n",
    "\n",
    "### Harmonic Mean\n",
    "\n",
    "$$Harmonic Mean = \\frac{n}{\\sum\\frac{1}{ExecutionTimeRation_i}}$$\n",
    "\n",
    "* Gives more weight to smaller differences\n",
    "\n",
    "Mathematical relationship:\n",
    "$$harmonic \\le geometric \\le arithmetic$$\n",
    "\n",
    "### SPEC Benchmark Evolution\n",
    "* A suite of benchmarks\n",
    "* Changes of included programs reflect changes in computer usage at the time\n",
    "* Uses geometric mean speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
